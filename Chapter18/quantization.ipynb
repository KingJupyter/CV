{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PacktPublishing/Modern-Computer-Vision-with-PyTorch-2E/blob/main/Chapter18/quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ggtWhvNjlWfO"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "  from torch_snippets import *\n",
    "except:\n",
    "  %pip install torch-snippets gitPython lovely-tensors\n",
    "  from torch_snippets import *\n",
    "\n",
    "from git import Repo\n",
    "\n",
    "repository_url = 'https://github.com/sizhky/quantization'\n",
    "destination_directory = '/content/quantization'\n",
    "if exists(destination_directory):\n",
    "  repo = Repo(destination_directory)\n",
    "else:\n",
    "  repo = Repo.clone_from(repository_url, destination_directory)\n",
    "\n",
    "%cd {destination_directory}\n",
    "%pip install -qq -r requirements.txt # this will take about 5 min of time\n",
    "%pip install -U torchvision\n",
    "%pip install -U torch-tensorrt\n",
    "# print(repo.git.pull('origin', 'main'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4_DGZ9Pz7ed"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eH6xwiJDam10",
    "outputId": "a09e3f1e-530f-4a91-89d8-bfeed3fb71ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_tensorrt\n",
    "torch_tensorrt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vmhVRnHoExo",
    "outputId": "bfe326e3-6b7c-4f96-8f61-49d824e3cdb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DEBUG=true\n",
      "python -m src.defect_classification.train\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100% 528M/528M [00:05<00:00, 108MB/s]\n",
      "Downloading readme: 100% 495/495 [00:00<00:00, 3.35MB/s]\n",
      "Downloading data: 100% 306M/306M [00:01<00:00, 171MB/s]\n",
      "Downloading data: 100% 305M/305M [00:01<00:00, 176MB/s]\n",
      "Downloading data: 100% 263M/263M [00:03<00:00, 71.0MB/s]\n",
      "Generating train split: 100% 2331/2331 [00:04<00:00, 529.93 examples/s]\n",
      "Generating valid split: 100% 1004/1004 [00:01<00:00, 715.76 examples/s]\n",
      "Class Balance\n",
      " \n",
      "```↯ AttrDict ↯\n",
      "train\n",
      "  non_defect - \u001b[1;36m50\u001b[0m \u001b[1m(\u001b[0mint\u001b[1m)\u001b[0m\n",
      "  defect - \u001b[1;36m50\u001b[0m \u001b[1m(\u001b[0mint\u001b[1m)\u001b[0m\n",
      "valid\n",
      "  non_defect - \u001b[1;36m50\u001b[0m \u001b[1m(\u001b[0mint\u001b[1m)\u001b[0m\n",
      "  defect - \u001b[1;36m50\u001b[0m \u001b[1m(\u001b[0mint\u001b[1m)\u001b[0m\n",
      "\n",
      "```\n",
      "\n",
      "Map: 100% 100/100 [00:19<00:00,  5.24 examples/s]\n",
      "Map: 100% 100/100 [00:17<00:00,  5.67 examples/s]\n",
      "Epoch: \u001b[1;36m1\u001b[0m \u001b[33mtrain_epoch_loss\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.690\u001b[0m\n",
      "Epoch: \u001b[1;36m11\u001b[0m \u001b[33mtrain_epoch_loss\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.584\u001b[0m\n",
      "Epoch: \u001b[1;36m21\u001b[0m \u001b[33mtrain_epoch_loss\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.472\u001b[0m\n",
      "Saved model to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Change to `Debug=false` in the line below\n",
    "# to train on a larger dataset\n",
    "%env DEBUG=true\n",
    "!make train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQAvk8xYz8kJ"
   },
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoGQDq__ocy_",
    "outputId": "60e91a90-d52d-4948-eb5c-9ee41ea7d12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m src.defect_classification.basic_benchmark\n",
      "Started computing roc auc score\u001b[33m...\u001b[0m\n",
      "Map: 100% 100/100 [00:18<00:00,  5.38 examples/s]\n",
      "ROC AUC Score: \u001b[1;36m0.89\u001b[0m\n",
      "Started benchmarks\u001b[33m...\u001b[0m\n",
      "Average batch time: \u001b[1;36m118.61\u001b[0m ms\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "!make basic-benchmark\n",
    "# visit makefile for the actual python command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKmDhyt1dcxU"
   },
   "source": [
    "```python\n",
    "model = torch.load('model.pth').eval()\n",
    "\n",
    "input_shape = (32,3,224,224)\n",
    "trt_model_hp = torch_tensorrt.compile(\n",
    "    model,\n",
    "    inputs=[torch_tensorrt.Input(input_shape)],\n",
    "    enabled_precisions= {torch_tensorrt.dtype.half} # Run with FP16\n",
    ")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datasets import load_dataset\n",
    "from src.defect_classification.train import process_example, DefectsDataset\n",
    "\n",
    "def get_roc_auc_score(model):\n",
    "    print(\"Started computing roc auc score...\")\n",
    "    predictions, actuals = [], []\n",
    "\n",
    "    val_ds = load_dataset('sizhkhy/kolektor_sdd2', split=\"valid[:50]+valid[-50:]\")\n",
    "    val_ds = val_ds.map(process_example).remove_columns(['split', 'path'])\n",
    "    val_ds.set_format(\"pt\", columns=[\"image\", \"label\"], output_all_columns=True)\n",
    "    val_ds = DefectsDataset(val_ds)\n",
    "    val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "    for ix, batch in enumerate(iter(val_dl)):\n",
    "        x, y = batch\n",
    "        if isinstance(model, nn.Module):\n",
    "          prediction = model(x.cuda()).detach().cpu().numpy().tolist()\n",
    "        else: # half/int8 model\n",
    "          prediction = model(x.cuda())[0].detach().cpu().numpy().tolist()\n",
    "        predictions.extend(prediction)\n",
    "        actuals.extend(y.detach().cpu().numpy().tolist())\n",
    "\n",
    "    actuals = flatten(actuals)\n",
    "    predictions = flatten(predictions)\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(actuals, predictions):.2f}\")\n",
    "\n",
    "get_roc_auc_score(trt_model_hp)\n",
    "\n",
    "import time\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark(model, input_shape=(32, 3, 224, 224), nwarmup=5, nruns=100):\n",
    "    print(\"Started benchmarks...\")\n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_data = input_data.to(\"cuda\")\n",
    "    for _ in range(nwarmup):\n",
    "        model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    timings = []\n",
    "    for _ in range(nruns):\n",
    "        start_time = time.perf_counter()\n",
    "        model(input_data)\n",
    "        end_time = time.perf_counter()\n",
    "        timings.append(end_time - start_time)\n",
    "    timing = np.mean(timings)*1000\n",
    "    print(f'Average batch time: {timing:.2f} ms')\n",
    "\n",
    "benchmark(trt_model_hp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4J4pN1QtxXO",
    "outputId": "5ef67892-b996-47ea-fa9b-56ab6d35529d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m src.defect_classification.fp16_benchmark\n",
      "INFO:datasets:PyTorch version 2.2.1+cu121 available.\n",
      "INFO:datasets:Polars version 0.20.2 available.\n",
      "INFO:datasets:TensorFlow version 2.15.0 available.\n",
      "INFO:datasets:JAX version 0.4.26 available.\n",
      "Loading trt model...\n",
      "INFO:torch_tensorrt._compile:ir was set to default, using dynamo as ir\n",
      "INFO:torch_tensorrt.dynamo._compiler:Compilation Settings: CompilationSettings(precision=torch.float16, debug=False, workspace_size=0, min_block_size=5, torch_executed_ops=set(), pass_through_build_failures=False, max_aux_streams=None, version_compatible=False, optimization_level=None, use_python_runtime=False, truncate_long_and_double=False, use_fast_partitioner=True, enable_experimental_decompositions=False, device=Device(type=DeviceType.GPU, gpu_id=0), require_full_compilation=False, disable_tf32=False, sparse_weights=False, refit=False, engine_capability=<EngineCapability.DEFAULT: 0>, num_avg_timing_iters=1, dla_sram_size=1048576, dla_local_dram_size=1073741824, dla_global_dram_size=536870912, output_format='exported_program')\n",
      "\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT INetwork construction elapsed time: 0:00:00.148884\n",
      "[05/02/2024-17:26:18] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "[05/02/2024-17:26:18] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "[05/02/2024-17:26:18] [TRT] [W] Check verbose logs for the list of affected weights.\n",
      "[05/02/2024-17:26:18] [TRT] [W] - 15 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "[05/02/2024-17:26:18] [TRT] [W] - 10 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:Build TRT engine elapsed time: 0:01:26.446164\n",
      "INFO:torch_tensorrt.dynamo.conversion._TRTInterpreter:TRT Engine uses: 411041792 bytes of Memory\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_export/exported_program.py:333: UserWarning: Unable to execute the generated python source code from the graph. The graph module will no longer be directly callable, but you can still run the ExportedProgram, and if needed, you can run the graph module eagerly using torch.fx.Interpreter.\n",
      "  warnings.warn(\n",
      "Started computing roc auc score\u001b[33m...\u001b[0m\n",
      "ROC AUC Score: \u001b[1;36m0.89\u001b[0m\n",
      "Started benchmarks\u001b[33m...\u001b[0m\n",
      "Average batch time: \u001b[1;36m21.10\u001b[0m ms\n"
     ]
    }
   ],
   "source": [
    "# visit makefile for the actual python command\n",
    "!make fp16-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OkydFdAAM3BS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
