{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PacktPublishing/Modern-Computer-Vision-with-PyTorch-2E/blob/main/Chapter18/convert_to_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggtWhvNjlWfO"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "  from torch_snippets import *\n",
    "except:\n",
    "  %pip install torch-snippets gitPython lovely-tensors\n",
    "  from torch_snippets import *\n",
    "\n",
    "from git import Repo\n",
    "\n",
    "repository_url = 'https://github.com/sizhky/quantization'\n",
    "destination_directory = '/content/quantization'\n",
    "if exists(destination_directory):\n",
    "  repo = Repo(destination_directory)\n",
    "else:\n",
    "  repo = Repo.clone_from(repository_url, destination_directory)\n",
    "\n",
    "%cd {destination_directory}\n",
    "%pip install -qq -r requirements.txt # this will take about 5 min of time\n",
    "%pip install onnxruntime-gpu onnx\n",
    "%pip install -U torchvision\n",
    "# print(repo.git.pull('origin', 'main'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4_DGZ9Pz7ed"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vmhVRnHoExo",
    "outputId": "e1cbfd0d-22e9-4ae3-f5f5-3c309cf73c06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DEBUG=true\n",
      "python -m src.defect_classification.train\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100% 528M/528M [00:07<00:00, 78.3MB/s]\n",
      "Downloading readme: 100% 495/495 [00:00<00:00, 2.57MB/s]\n",
      "Downloading data: 100% 306M/306M [00:07<00:00, 38.9MB/s]\n",
      "Downloading data: 100% 305M/305M [00:06<00:00, 46.0MB/s]\n",
      "Downloading data: 100% 263M/263M [00:06<00:00, 41.7MB/s]\n",
      "Generating train split: 100% 2331/2331 [00:02<00:00, 1049.98 examples/s]\n",
      "Generating valid split: 100% 1004/1004 [00:01<00:00, 884.39 examples/s]\n",
      "Class Balance\n",
      " \n",
      "```↯ AttrDict ↯\n",
      "train\n",
      "  non_defect - 50 (int)\n",
      "  defect - 50 (int)\n",
      "valid\n",
      "  non_defect - 50 (int)\n",
      "  defect - 50 (int)\n",
      "\n",
      "```\n",
      "\n",
      "Map: 100% 100/100 [00:19<00:00,  5.22 examples/s]\n",
      "Map: 100% 100/100 [00:19<00:00,  5.03 examples/s]\n",
      "Epoch: 1 train_epoch_loss=0.689\n",
      "Epoch: 11 train_epoch_loss=0.592\n",
      "Epoch: 21 train_epoch_loss=0.478\n",
      "Saved model to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Change to `Debug=false` in the line below\n",
    "# to train on a larger dataset\n",
    "%env DEBUG=true\n",
    "!make train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQAvk8xYz8kJ"
   },
   "source": [
    "# Conversion to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoGQDq__ocy_"
   },
   "outputs": [],
   "source": [
    "sys.path.append('src')\n",
    "from defect_classification.model import SDD\n",
    "from defect_classification.train import process_example, DefectsDataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JL_SiDXrgexO"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "val_ds = load_dataset('sizhkhy/kolektor_sdd2', split=\"valid[:50]+valid[-50:]\")\n",
    "val_ds = val_ds.map(process_example).remove_columns(['split', 'path'])\n",
    "val_ds.set_format(\"pt\", columns=[\"image\", \"label\"], output_all_columns=True)\n",
    "val_ds = DefectsDataset(val_ds)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIl8GQHsjfE5"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "device = 'cpu'\n",
    "model = torch.load('model.pth').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before converting our model into ONNX format, we will now create an input tensor and use it to make predictions. There are two primary motivations for this exercise.\n",
    "\n",
    "Firstly, by comparing the outputs of the PyTorch model with those of the ONNX model, we can verify that both models produce identical results. This ensures that our conversion from PyTorch to ONNX has been successful\n",
    "and that we can rely on the converted model for inference purposes.\n",
    "\n",
    "Secondly, by measuring the time taken by each model to generate predictions, we can compare their performance in terms of speed and efficiency. This information will be useful in determining which model is better\n",
    "suited for deployment in a production environment, where rapid processing times are critical.\n",
    "\n",
    "In the following cell, we will create an input tensor and use it to predict using the PyTorch model. We will then compare this outputs and timing results to draw conclusions about it's performance with ONNX in a few cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFQHAu0Aik46",
    "outputId": "ddf36f30-b174-4256-a437-ba8279547acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by pytorch model on sample input\n",
      "CPU times: user 15.2 s, sys: 2.81 s, total: 18 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "# prompt: export to onnx with dynamic axes\n",
    "model.eval()\n",
    "i, _ = next(iter(val_dl))\n",
    "with torch.no_grad():\n",
    "    # first prediction is model warmup\n",
    "    model(i.to(device))\n",
    "    print(f'Time taken by pytorch model on sample input')\n",
    "    %time pred_pytorch_model = model(i.to(device))\n",
    "    pred_pytorch_model = pred_pytorch_model.to(device).numpy().reshape(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the model in to ONNX format - \n",
    "\n",
    "Specifying input and output names for the model. By specifying input and output names, we're a clear understanding of what data types are expected as inputs and outputs for the model. This makes it easier for other frameworks or tools to consume the exported model, regardless of their native data type representations. The input and output names also help provide a common language for all frameworks to understand and work with the model.\n",
    "  - input_names = ['image']: This sets the input name(s) of the model. In this case, there is only one input named 'image'.\n",
    "  - output_names = ['label']: This sets the output name(s) of the model. Again, there is only one output named 'label'.\n",
    "\n",
    "Defining dynamic axes\n",
    "\n",
    "The dynamic_axes dictionary defines dynamic axes for the ONNX model. In this case:\n",
    "  - {0: 'batch_size'}: This specifies that the first axis (axis 0) of both the input and output tensors should be labeled as 'batch_size'. Dynamic axes are used to specify axes that will have varying sizes depending on the batch size.\n",
    "\n",
    "Specifying the ONNX file path\n",
    "  - onnx_file_path = 'sdd_base.onnx': This sets the file name and path for the exported ONNX model, which will be named 'sdd_base.onnx'.\n",
    "\n",
    "The final line exports the PyTorch model to the specified ONNX file:\n",
    "  - torch.onnx.export(model, i[:1].to(device), f, export_params=True, verbose=False, opset_version=13, do_constant_folding=True, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes)\n",
    "\n",
    "Here's what each argument does:\n",
    "  - model: This is the PyTorch model to be exported.\n",
    "  - i[:1].to(device): This specifies an example input tensor(s) for the export. This allows the export process to generate a more accurate and complete ONNX graph structure.\n",
    "  - f: This is the file object opened in write binary mode ('wb') earlier.\n",
    "  - export_params=True: This tells PyTorch to export the model's parameters along with the graph structure.\n",
    "  - verbose=False: This sets the verbosity level for the export process. In this case, it will not print any output.\n",
    "  - opset_version=13: This specifies the Open Neural Network Exchange (ONNX) opset version that will be used for the exported model. Opsets are used to specify the version of the ONNX format being used.\n",
    "  - do_constant_folding=True: This tells PyTorch to identify constant values in the model, and pack the architecture in a way which can reduce the size of the exported graph.\n",
    "  - input_names=input_names, output_names=output_names, and dynamic_axes=dynamic_axes : These specify the input names, output names, and dynamic axes for the exported ONNX model, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGnodrRlhmWS"
   },
   "outputs": [],
   "source": [
    "input_names = ['image']\n",
    "output_names = ['label']\n",
    "dynamic_axes = {'image': {0: 'batch_size'}, 'label': {0: 'batch_size'}}\n",
    "onnx_file_path = 'sdd_base.onnx'\n",
    "with open(onnx_file_path, 'wb') as f:\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        i[:1].to(device),\n",
    "        f,\n",
    "        export_params=True,\n",
    "        verbose=False,\n",
    "        opset_version=13,\n",
    "        do_constant_folding=True,\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes=dynamic_axes\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an onnx model, let's load it, predict and measure the time for prediction. \n",
    "\n",
    "Loading the ONNX model on GPU\n",
    "The next line loads the ONNX model sdd_base.onnx using the InferenceSession constructor. The providers parameter is set to ['CPUExecutionProvider'], which means that the model will be executed on the CPU (not GPU, as specified).\n",
    "\n",
    "Getting input and output names\n",
    "The following two lines get the input and output names from the loaded ONNX model:\n",
    "  - input_name = session.get_inputs()[0].name: This gets the name of the first input tensor in the model.\n",
    "  - output_name = session.get_outputs()[0].name: This gets the name of the first output tensor in the model.\n",
    "\n",
    "Preparing sample input data\n",
    "The next line prepares a sample input tensor for making predictions:\n",
    "  - input = i.numpy(): Assuming i is a PyTorch tensor, this line converts it to a NumPy array, which can be used as input to the ONNX model.\n",
    "\n",
    "Making the first prediction (model warmup)\n",
    "The final lines make the first prediction using the loaded ONNX model:\n",
    "  - pred_onnx = session.run(None, {input_name: input})[0]: This runs the ONNX model on the prepared input data. The None argument indicates that there are no additional inputs to provide. The input_name: input dictionary maps the input name to the prepared input data.\n",
    "\n",
    "Warming up a model involves running it with sample inputs to initialize its internal state so that the subsequet predictions are consistently faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAgpUVW2iyKE",
    "outputId": "e9f44077-a7e8-4260-8a77-c6535a9afbb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by ONNX model on same input\n",
      "CPU times: user 13.7 s, sys: 468 ms, total: 14.1 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "# load the onnx model on gpu\n",
    "session = InferenceSession('sdd_base.onnx', providers=['CPUExecutionProvider'])\n",
    "# make sample prediction\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "input = i.numpy()\n",
    "\n",
    "# first prediction is model warmup\n",
    "pred_onnx = session.run(None, {input_name: input})[0]\n",
    "print(f'Time taken by ONNX model on same input')\n",
    "%time pred_onnx = session.run(None, {input_name: input})\n",
    "pred____onnx_model = pred_onnx[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4yHYb6boE5t",
    "outputId": "1aebc4c3-26a5-4c50-b074-da167f1cd8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the pytorch and onnx model's predictions are identical - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Both the pytorch and onnx model\\'s predictions are identical - ')\n",
    "np.allclose(\n",
    "    pred_pytorch_model,\n",
    "    pred____onnx_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_O5VinDMpaXy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
